from flask import Flask, Response
import cv2
import numpy as np
import torch
import time
from ultralytics import YOLO

app = Flask(__name__)

# Camera stream URL c·ªßa b·∫°n
CAM_URL = "http://192.168.137.242:8080/video/tapo"

# Load YOLOv8s
model = YOLO("yolov8s.pt")
model.to("cpu")

# C√°c class xe trong COCO
VEHICLE_CLASS_IDS = [1, 2, 3, 5, 7]

# C·∫•u h√¨nh
PIXEL_TO_METER = 0.12
CONF_THRES = 0.15
PROCESS_INTERVAL = 60   # x·ª≠ l√Ω 1 l·∫ßn m·ªói ph√∫t

# Bi·∫øn l∆∞u previous positions ƒë·ªÉ t√≠nh speed
prev_positions = {}
prev_time = None


def classify_traffic(density):
    if density <= 0.05:
        return 1
    if density < 0.4:
        return 2
    elif density < 0.8:
        return 3
    return 3


def generate():

    global prev_positions, prev_time

    cap = cv2.VideoCapture(CAM_URL)

    if not cap.isOpened():
        print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c camera stream!")
        return

    print("üì° Camera stream ƒë√£ k·∫øt n·ªëi...")

    density = 0
    avg_speed = 0
    vehicle_count = 0
    level = 1
    last_process = 0
    last_boxes = []   # d√πng ƒë·ªÉ hi·ªÉn th·ªã

    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ö† M·∫•t k·∫øt n·ªëi camera, th·ª≠ l·∫°i...")
            cap = cv2.VideoCapture(CAM_URL)
            continue

        # Resize nh·∫π ƒë·ªÉ YOLO nhanh h∆°n
        small = cv2.resize(frame, (640, 360))
        h, w = small.shape[:2]

        # ROI b·∫°n ƒë√£ ch·ªçn
        roi_x1, roi_y1 = 120, 160
        roi_x2, roi_y2 = 520, 340
        roi = small[roi_y1:roi_y2, roi_x1:roi_x2]

        now = time.time()
        detect_now = (now - last_process >= PROCESS_INTERVAL)

        if detect_now:
            last_process = now
            last_boxes = []
            curr_positions = {}
            vehicle_area = 0
            vehicle_count = 0

            # YOLO detect
            with torch.no_grad():
                results = model.predict(
                    roi,
                    conf=CONF_THRES,
                    imgsz=416,
                    classes=VEHICLE_CLASS_IDS,
                    verbose=False
                )[0]

            ROI_area = roi.shape[0] * roi.shape[1]

            # X·ª≠ l√Ω box
            for idx, box in enumerate(results.boxes):
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)

                # map to full frame
                x1 += roi_x1
                x2 += roi_x1
                y1 += roi_y1
                y2 += roi_y1

                # v·∫Ω l·∫°i sau
                last_boxes.append((x1, y1, x2, y2))

                vehicle_count += 1
                vehicle_area += (x2 - x1) * (y2 - y1)

                cx = (x1 + x2) // 2
                cy = (y1 + y2) // 2
                curr_positions[idx] = (cx, cy)

            # Density
            density = min(vehicle_area / ROI_area, 1.0)

            # Speed t√≠nh theo 1 ph√∫t
            if prev_time is not None:
                speeds = []
                dt = now - prev_time
                for vid, (cx2, cy2) in curr_positions.items():
                    if vid in prev_positions:
                        cx1, cy1 = prev_positions[vid]
                        pix = np.sqrt((cx2 - cx1)**2 + (cy2 - cy1)**2)
                        meter = pix * PIXEL_TO_METER
                        speed = meter / dt
                        speeds.append(speed)
                avg_speed = float(np.mean(speeds)) if speeds else 0

            # L∆∞u cho cycle sau
            prev_positions = curr_positions
            prev_time = now

            # Level
            level = classify_traffic(density)

        # -------------------------------------------------------
        # V·∫º BOX T·ª™ L·∫¶N X·ª¨ L√ù G·∫¶N NH·∫§T
        # -------------------------------------------------------
        for (x1, y1, x2, y2) in last_boxes:
            cv2.rectangle(small, (x1, y1), (x2, y2), (0,255,0), 2)

        # V·∫Ω ROI
        cv2.rectangle(small, (roi_x1, roi_y1), (roi_x2, roi_y2), (255,0,0), 2)

        # INFO
        cv2.putText(small, f"Veh: {vehicle_count}", (20,40),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0),2)

        cv2.putText(small, f"Dens: {density:.2f}", (20,70),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8,(0,255,255),2)

        cv2.putText(small, f"Speed: {avg_speed:.2f}", (20,100),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8,(255,255,0),2)

        cv2.putText(small, f"Level: {level}", (20,130),
                    cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,255),2)

        # Encode JPEG ƒë·ªÉ stream
        ret, jpeg = cv2.imencode('.jpg', small)
        yield (b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" +
               jpeg.tobytes() + b"\r\n")


@app.route("/")
def home():
    return "<h2>YOLOv8 Live Traffic Monitor (Camera Tapo)</h2><img src='/video'>"


@app.route("/video")
def video():
    return Response(generate(),
                    mimetype="multipart/x-mixed-replace; boundary=frame")


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, threaded=True)
